{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1 \n",
    "\n",
    "<font color = 'red'>Codes below each question will be graded as the answer of that questions. Only correct codes without syntax error will receive full credit. </font>\n",
    "\n",
    "### Question 1: (1 point)\n",
    "1. Run the following code cell once to download the dataset into the local directory. The name of the downloaded file will be ``train.csv``\n",
    "\n",
    "1. Make a pandas dataframe out of ``train.csv``\n",
    "\n",
    "1. The goal of this project is to predict ``critical_temp``\n",
    "\n",
    "1. Define feature set X and target set y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8105k  100 8105k    0     0  4052k      0  0:00:02  0:00:02 --:--:-- 2879k\n",
      "File Name                                             Modified             Size\n",
      "unique_m.csv                                   2018-10-12 08:25:44      4291603\n",
      "train.csv                                      2018-10-12 08:25:04     23859780\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile \n",
    "\n",
    "!curl -o superconduct.zip http://archive.ics.uci.edu/ml/machine-learning-databases/00464/superconduct.zip?accessType=DOWNLOAD\n",
    "\n",
    "with ZipFile('superconduct.zip', 'r') as zip: \n",
    "    # printing all the contents of the zip file \n",
    "    zip.printdir() \n",
    "  \n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zip.extractall() \n",
    "    print('Done!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset in as Train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studying structure of dataset through using head() command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                   4         88.944468             57.862692   \n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          66.361592              36.116612             1.181795   \n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                 1.062396          122.90607              31.794921   \n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "\n",
       "   std_atomic_mass      ...        wtd_mean_Valence  gmean_Valence  \\\n",
       "0        51.968828      ...                2.257143       2.213364   \n",
       "1        47.094633      ...                2.257143       1.888175   \n",
       "2        51.968828      ...                2.271429       2.213364   \n",
       "3        51.968828      ...                2.264286       2.213364   \n",
       "4        51.968828      ...                2.242857       2.213364   \n",
       "\n",
       "   wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "0           2.219783         1.368922             1.066221              1   \n",
       "1           2.210679         1.557113             1.047221              2   \n",
       "2           2.232679         1.368922             1.029175              1   \n",
       "3           2.226222         1.368922             1.048834              1   \n",
       "4           2.206963         1.368922             1.096052              1   \n",
       "\n",
       "   wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp  \n",
       "0           1.085714     0.433013         0.437059           29.0  \n",
       "1           1.128571     0.632456         0.468606           26.0  \n",
       "2           1.114286     0.433013         0.444697           19.0  \n",
       "3           1.100000     0.433013         0.440952           22.0  \n",
       "4           1.057143     0.433013         0.428809           23.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21263, 82)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pop out Critical Temp from dataset and set as target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = dataset.pop('critical_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set feature set X using remainder columns in dataset after pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: (2 points)\n",
    "\n",
    "Consider the *unsupervised model* ``StandardScaler`` to transform ``X`` into ``X_scaled`` pandas dataframe with the same column names as ``X``. Show the head of ``X_scaled``. \n",
    "\n",
    "**Note:** Use the following line of code to import ``StandardScaler``: \n",
    "``` Python \n",
    "from sklearn.preprocessing import StandardScaler```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_Valence</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                   4         88.944468             57.862692   \n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          66.361592              36.116612             1.181795   \n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                 1.062396          122.90607              31.794921   \n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "\n",
       "   std_atomic_mass       ...         mean_Valence  wtd_mean_Valence  \\\n",
       "0        51.968828       ...                 2.25          2.257143   \n",
       "1        47.094633       ...                 2.00          2.257143   \n",
       "2        51.968828       ...                 2.25          2.271429   \n",
       "3        51.968828       ...                 2.25          2.264286   \n",
       "4        51.968828       ...                 2.25          2.242857   \n",
       "\n",
       "   gmean_Valence  wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  \\\n",
       "0       2.213364           2.219783         1.368922             1.066221   \n",
       "1       1.888175           2.210679         1.557113             1.047221   \n",
       "2       2.213364           2.232679         1.368922             1.029175   \n",
       "3       2.213364           2.226222         1.368922             1.048834   \n",
       "4       2.213364           2.206963         1.368922             1.096052   \n",
       "\n",
       "   range_Valence  wtd_range_Valence  std_Valence  wtd_std_Valence  \n",
       "0              1           1.085714     0.433013         0.437059  \n",
       "1              2           1.128571     0.632456         0.468606  \n",
       "2              1           1.114286     0.433013         0.444697  \n",
       "3              1           1.100000     0.433013         0.440952  \n",
       "4              1           1.057143     0.433013         0.428809  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Numpy array back into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_Valence</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.080058</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>-0.451651</td>\n",
       "      <td>-0.158850</td>\n",
       "      <td>-0.611819</td>\n",
       "      <td>0.044358</td>\n",
       "      <td>-0.003707</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>-0.053039</td>\n",
       "      <td>0.378186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907755</td>\n",
       "      <td>-0.752156</td>\n",
       "      <td>-0.805912</td>\n",
       "      <td>-0.711705</td>\n",
       "      <td>0.186292</td>\n",
       "      <td>0.035183</td>\n",
       "      <td>-0.837959</td>\n",
       "      <td>-0.406166</td>\n",
       "      <td>-0.838372</td>\n",
       "      <td>-0.520070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.614744</td>\n",
       "      <td>0.174269</td>\n",
       "      <td>-0.432071</td>\n",
       "      <td>0.059368</td>\n",
       "      <td>-0.604180</td>\n",
       "      <td>0.777430</td>\n",
       "      <td>-0.015267</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.134901</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.147084</td>\n",
       "      <td>-0.752156</td>\n",
       "      <td>-1.116731</td>\n",
       "      <td>-0.719454</td>\n",
       "      <td>0.664971</td>\n",
       "      <td>-0.014779</td>\n",
       "      <td>-0.033011</td>\n",
       "      <td>-0.362352</td>\n",
       "      <td>-0.426866</td>\n",
       "      <td>-0.450821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.080058</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>-0.450978</td>\n",
       "      <td>-0.158850</td>\n",
       "      <td>-0.611658</td>\n",
       "      <td>0.044358</td>\n",
       "      <td>-0.218984</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>0.093294</td>\n",
       "      <td>0.378186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907755</td>\n",
       "      <td>-0.740164</td>\n",
       "      <td>-0.805912</td>\n",
       "      <td>-0.700728</td>\n",
       "      <td>0.186292</td>\n",
       "      <td>-0.062235</td>\n",
       "      <td>-0.837959</td>\n",
       "      <td>-0.376957</td>\n",
       "      <td>-0.838372</td>\n",
       "      <td>-0.503304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.080058</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>-0.451314</td>\n",
       "      <td>-0.158850</td>\n",
       "      <td>-0.611739</td>\n",
       "      <td>0.044358</td>\n",
       "      <td>-0.103615</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.378186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907755</td>\n",
       "      <td>-0.746160</td>\n",
       "      <td>-0.805912</td>\n",
       "      <td>-0.706224</td>\n",
       "      <td>0.186292</td>\n",
       "      <td>-0.010538</td>\n",
       "      <td>-0.837959</td>\n",
       "      <td>-0.391562</td>\n",
       "      <td>-0.838372</td>\n",
       "      <td>-0.511524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.080058</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>-0.452324</td>\n",
       "      <td>-0.158850</td>\n",
       "      <td>-0.611980</td>\n",
       "      <td>0.044358</td>\n",
       "      <td>0.162775</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>-0.199372</td>\n",
       "      <td>0.378186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907755</td>\n",
       "      <td>-0.764149</td>\n",
       "      <td>-0.805912</td>\n",
       "      <td>-0.722618</td>\n",
       "      <td>0.186292</td>\n",
       "      <td>0.113627</td>\n",
       "      <td>-0.837959</td>\n",
       "      <td>-0.435376</td>\n",
       "      <td>-0.838372</td>\n",
       "      <td>-0.538178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0           -0.080058          0.046733             -0.451651   \n",
       "1            0.614744          0.174269             -0.432071   \n",
       "2           -0.080058          0.046733             -0.450978   \n",
       "3           -0.080058          0.046733             -0.451314   \n",
       "4           -0.080058          0.046733             -0.452324   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          -0.158850              -0.611819             0.044358   \n",
       "1           0.059368              -0.604180             0.777430   \n",
       "2          -0.158850              -0.611658             0.044358   \n",
       "3          -0.158850              -0.611739             0.044358   \n",
       "4          -0.158850              -0.611980             0.044358   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                -0.003707           0.133725              -0.053039   \n",
       "1                -0.015267           0.133725               0.108900   \n",
       "2                -0.218984           0.133725               0.093294   \n",
       "3                -0.103615           0.133725               0.020128   \n",
       "4                 0.162775           0.133725              -0.199372   \n",
       "\n",
       "   std_atomic_mass       ...         mean_Valence  wtd_mean_Valence  \\\n",
       "0         0.378186       ...            -0.907755         -0.752156   \n",
       "1         0.134901       ...            -1.147084         -0.752156   \n",
       "2         0.378186       ...            -0.907755         -0.740164   \n",
       "3         0.378186       ...            -0.907755         -0.746160   \n",
       "4         0.378186       ...            -0.907755         -0.764149   \n",
       "\n",
       "   gmean_Valence  wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  \\\n",
       "0      -0.805912          -0.711705         0.186292             0.035183   \n",
       "1      -1.116731          -0.719454         0.664971            -0.014779   \n",
       "2      -0.805912          -0.700728         0.186292            -0.062235   \n",
       "3      -0.805912          -0.706224         0.186292            -0.010538   \n",
       "4      -0.805912          -0.722618         0.186292             0.113627   \n",
       "\n",
       "   range_Valence  wtd_range_Valence  std_Valence  wtd_std_Valence  \n",
       "0      -0.837959          -0.406166    -0.838372        -0.520070  \n",
       "1      -0.033011          -0.362352    -0.426866        -0.450821  \n",
       "2      -0.837959          -0.376957    -0.838372        -0.503304  \n",
       "3      -0.837959          -0.391562    -0.838372        -0.511524  \n",
       "4      -0.837959          -0.435376    -0.838372        -0.538178  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: (2 point)\n",
    "Reduce the dimensions of ``X_scaled`` to 2, using unsupervised methods ``PCA``.\n",
    "```Python\n",
    "from sklearn.decomposition import PCA```\n",
    "\n",
    "Then use a cross validation method with 5 folds to find average train and test score for a LinearRegression model on transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2D = model.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.66448679,  0.99164268],\n",
       "       [-4.55546842, -0.21458475],\n",
       "       [-3.48817626,  1.05516726],\n",
       "       ...,\n",
       "       [10.47746178, -0.93194298],\n",
       "       [ 9.77188538, -1.00134503],\n",
       "       [ 3.91560139,  1.44638504]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Weiyang/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2D, y, random_state=777, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = cross_val_score(model, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4572260527337197"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = cross_val_score(model, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4637601853487062"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: (3 points)\n",
    "\n",
    "***plot*** the validation curve for ``PCA`` with number components between 2 and 10 and ``LinearRegression`` model. Which number of components gives the optimal trade-off between bias and variance? \n",
    "\n",
    "You can use the following pipeline: \n",
    "```Python \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def model(n_components = 2, **kwargs):\n",
    "    return make_pipeline(PCA(n_components), \n",
    "                       LinearRegression(**kwargs))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(n_components = 2, **kwargs):\n",
    "    return make_pipeline(PCA(n_components), \n",
    "                       LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = np.arange(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a2447a5f8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAE/CAYAAAB4o6baAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNY5nAUpno+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2388bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_score, val_score = validation_curve(model(), X_scaled, y, 'pca__n_components', n_components, cv=7)\n",
    "\n",
    "plt.subplots(figsize=(10,5))\n",
    "plt.plot(n_components, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(n_components, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('No. of Components')\n",
    "plt.ylabel('Score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
